{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Data Preprocessing and Embedding Creation\n",
    "\n",
    "**Objective:** This notebook walks through the steps of loading documents, splitting them into chunks, generating embeddings, and creating/saving a vector store (FAISS index).\n",
    "\n",
    "**Steps:**\n",
    "1. Setup: Import necessary libraries and configure paths.\n",
    "2. Load Configuration: Access settings from `src/config.py`.\n",
    "3. Load Documents: Use `data_processor.load_documents_from_directory`.\n",
    "4. Split Documents: Use `data_processor.split_documents_into_chunks`.\n",
    "5. Initialize Embedding Model: Use `vector_store.get_embedding_model`.\n",
    "6. Create and Save Vector Store: Use `vector_store.create_and_save_vector_store`.\n",
    "7. (Optional) Test Loading Vector Store: Verify the saved store can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to sys.path to allow imports from src\n",
    "# This assumes the notebook is in 'project-rag-demo/notebooks/'\n",
    "project_root = Path(os.getcwd()).parent \n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Now we can import from src\n",
    "from src import config\n",
    "from src.data_processor import load_documents_from_directory, split_documents_into_chunks\n",
    "from src.vector_store import get_embedding_model, create_and_save_vector_store, load_vector_store\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"OpenAI API Key Loaded: {'Yes' if config.OPENAI_API_KEY else 'No (Please check .env file!)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data Path: {config.DATA_PATH}\")\n",
    "print(f\"Vector Store Path: {config.VECTOR_STORE_PATH}\")\n",
    "print(f\"Chunk Size: {config.CHUNK_SIZE}\")\n",
    "print(f\"Chunk Overlap: {config.CHUNK_OVERLAP}\")\n",
    "print(f\"Embedding Model: {config.EMBEDDING_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = load_documents_from_directory(config.DATA_PATH)\n",
    "if raw_documents:\n",
    "    print(f\"Successfully loaded {len(raw_documents)} documents.\")\n",
    "    for i, doc in enumerate(raw_documents):\n",
    "        print(f\"--- Document {i+1} ---\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "        print(f\"Content (first 100 chars): {doc.page_content[:100].strip()}...\")\n",
    "else:\n",
    "    print(\"No documents found or loaded. Please check the 'data/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if raw_documents:\n",
    "    document_chunks = split_documents_into_chunks(\n",
    "        raw_documents,\n",
    "        chunk_size=config.CHUNK_SIZE,\n",
    "        chunk_overlap=config.CHUNK_OVERLAP\n",
    "    )\n",
    "    print(f\"Split into {len(document_chunks)} chunks.\")\n",
    "    if document_chunks:\n",
    "        print(\"\\n--- First Chunk Example ---\")\n",
    "        print(f\"Content: {document_chunks[0].page_content[:300]}...\")\n",
    "        print(f\"Metadata: {document_chunks[0].metadata}\")\n",
    "else:\n",
    "    document_chunks = []\n",
    "    print(\"Skipping chunking as no documents were loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = get_embedding_model()\n",
    "if embeddings_model:\n",
    "    print(f\"Embedding model ({config.EMBEDDING_MODEL_NAME}) initialized successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to initialize embedding model. Check API key or model name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and Save Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_instance = None\n",
    "if document_chunks and embeddings_model:\n",
    "    # Ensure the parent directory for the index exists\n",
    "    config.VECTOR_STORE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    vector_store_instance = create_and_save_vector_store(\n",
    "        chunks=document_chunks, \n",
    "        embeddings_model=embeddings_model, \n",
    "        index_path=str(config.VECTOR_STORE_PATH)\n",
    "    )\n",
    "    if vector_store_instance:\n",
    "        print(f\"Vector store created and saved to {config.VECTOR_STORE_PATH}\")\n",
    "    else:\n",
    "        print(\"Failed to create or save vector store.\")\n",
    "elif not document_chunks:\n",
    "    print(\"Cannot create vector store: No document chunks available.\")\n",
    "elif not embeddings_model:\n",
    "    print(\"Cannot create vector store: Embedding model not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (Optional) Test Loading the Saved Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.VECTOR_STORE_PATH.exists() and embeddings_model:\n",
    "    print(f\"\\nAttempting to load vector store from: {config.VECTOR_STORE_PATH}\")\n",
    "    loaded_vs = load_vector_store(\n",
    "        index_path=str(config.VECTOR_STORE_PATH), \n",
    "        embeddings_model=embeddings_model\n",
    "    )\n",
    "    if loaded_vs:\n",
    "        print(\"Vector store loaded successfully for testing.\")\n",
    "        # You could try a sample search here if desired\n",
    "        # test_query = \"What is RAG?\"\n",
    "        # results = loaded_vs.similarity_search(test_query, k=1)\n",
    "        # if results:\n",
    "        #     print(f\"Test search for '{test_query}' found: {results[0].page_content[:100]}...\")\n",
    "    else:\n",
    "        print(\"Failed to load the saved vector store.\")\n",
    "else:\n",
    "    print(\"Skipping load test: Vector store file does not exist or embedding model not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- End of Notebook 1 ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}